Disretizing using the median for the classification dataset
https://medium.com/data-science/discretization-explained-a-visual-guide-with-code-examples-for-beginners-f056af9102fa

The use of Standard Scalar from sklearn
https://www.digitalocean.com/community/tutorials/standardscaler-function-in-python

The ADAM optimizer
https://arxiv.org/abs/1412.6980

https://www.datacamp.com/tutorial/adam-optimizer-tutorial

The Level of Dropout
https://towardsdatascience.com/dropout-in-neural-networks-47a162d621d9/#:~:text=The%20term%20%22dropout%22%20refers%20to,solves%20the%20problem%20of%20overfitting?

The ReLu Activation Function
https://towardsdatascience.com/activation-functions-in-neural-networks-how-to-choose-the-right-one-cb20414c04e5/#:~:text=Rectified%20Linear%20Unit%20(ReLU),learning%20process%20is%20significantly%20accelerated.

Rather than using the default 80/20 train test split, resort to using 5 cross validation for all models
https://scikit-learn.org/1.0/modules/generated/sklearn.model_selection.GroupKFold.html